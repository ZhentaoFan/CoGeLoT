# @package _global_

defaults:
  - trainer: default
  - /instance_preprocessor.yaml@model
  - model@model.model: from_their_policy
  - datamodule: evaluation
  - hydra: default
  - hardware: default
  - debug: null
  - _self_

task_name: "evaluate"

output_dir: ${hydra:runtime.output_dir}

# This is the seed they used in their example script
seed: 42

model:
  _target_: cogelot.models.EvaluationLightningModule

  environment:
    _target_: cogelot.environment.VIMAEnvironment.from_config
    seed: ${seed}
    # We're just giving it any task here, it will get changed during the steps
    task: 1
    partition: 1
    should_display_debug_window: true
    should_render_prompt: true
    should_hide_arm_rgb: false

trainer:
  max_epochs: 1

  # The evaluation is going to be deterministic so it's consistent per run/model
  deterministic: True

  logger:
    - _target_: pytorch_lightning.loggers.WandbLogger
      save_dir: ${output_dir}
      name: Their Model
      project: cogelot-downstream
      entity: pyop
      log_model: False
      offline: true

  # Override the callbacks with just the logging ones
  callbacks:
    - _target_: pytorch_lightning.callbacks.RichModelSummary
      max_depth: -1
    - _target_: pytorch_lightning.callbacks.RichProgressBar
