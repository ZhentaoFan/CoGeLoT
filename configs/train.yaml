# @package _global_

defaults:
  - _self_

  # Get the datamodule from the other config file
  - datamodule: from_local_files.yaml

  - trainer: cpu.yaml

  # The chosen policy will automatically be set to the model.policy
  - transformer_decoder@model.policy.transformer_decoder: their_vima.yaml

  # LR scheduler used for training
  - learning_rate_scheduler@model.lr_scheduler_partial_fn: vima.yaml

  # Set defaults for Hydra's logging and outputs
  - hydra: default.yaml

  # Update with hardware-specific changes
  - hardware: local.yaml

  # If you want to debug, then just run like `python train.py debug=default`
  - debug: null

  # For experiments
  - experiment: null

task_name: "train"

output_dir: ${hydra:runtime.output_dir}

seed: 1000

model:
  _target_: cogelot.models.VIMALightningModule

  optimizer_partial_fn:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 0.000001
    weight_decay: 0

  policy:
    _target_: cogelot.modules.policy.Policy
    embed_dim: 768

    pose_action_tokenizer:
      _target_: cogelot.modules.tokenizers.PoseActionTokenizer

    transformer_decoder: ???

    obj_encoder:
      _target_: vima.nn.ObjEncoder
      transformer_emb_dim: ${..embed_dim}
      views: ["front", "top"]
      vit_output_dim: ${.transformer_emb_dim}
      vit_resolution: 32
      vit_patch_size: 16
      vit_width: ${.transformer_emb_dim}
      vit_layers: 4
      vit_heads: 24
      bbox_mlp_hidden_dim: ${.transformer_emb_dim}
      bbox_mlp_hidden_depth: 2

    end_effector_encoder:
      _target_: vima.nn.Embedding
      num_embeddings: 2
      embedding_dim: 2

    obs_fusion_layer:
      _target_: torch.nn.Linear
      in_features:
        _target_: builtins.sum
        _convert_: all
        _args_:
          - - ${model.policy.obj_encoder.transformer_emb_dim}
            - ${model.policy.end_effector_encoder.embedding_dim}
      out_features: ${..embed_dim}

    action_encoder:
      _target_: cogelot.modules.embedders.VIMAContinuousActionEmbedder
      pose_action_tokenizer:
        _target_: cogelot.modules.tokenizers.PoseActionTokenizer
      embedder_per_pose_action:
        pose0_position:
          _target_: vima.nn.ContinuousActionEmbedding
          output_dim: 256
          input_dim: 3
          hidden_dim: 256
          hidden_depth: 1
        pose1_position:
          _target_: vima.nn.ContinuousActionEmbedding
          output_dim: 256
          input_dim: 3
          hidden_dim: 256
          hidden_depth: 1
        pose0_rotation:
          _target_: vima.nn.ContinuousActionEmbedding
          output_dim: 256
          input_dim: 4
          hidden_dim: 256
          hidden_depth: 1
        pose1_rotation:
          _target_: vima.nn.ContinuousActionEmbedding
          output_dim: 256
          input_dim: 4
          hidden_dim: 256
          hidden_depth: 1
      post_layer:
        _target_: torch.nn.LazyLinear
        out_features: ${...embed_dim}

    action_decoder:
      _target_: vima.nn.ActionDecoder
      _convert_: all
      input_dim: ${..embed_dim}
      action_dims:
        pose0_position: [50, 100, 50]
        pose1_position: [50, 100, 50]
        pose0_rotation: [50, 50, 50, 50]
        pose1_rotation: [50, 50, 50, 50]
      hidden_dim: 512
      hidden_depth: 2
      activation: "relu"
      norm_type: null
      last_layer_gain: 0.01

    prompt_embedding:
      _target_: vima.nn.WordEmbedding

    prompt_encoder:
      _target_: vima.nn.T5PromptEncoder

    prompt_obj_post_layer:
      _target_: vima.nn.build_mlp
      input_dim: ${..embed_dim}
      hidden_dim: ${.input_dim}
      output_dim: ${.hidden_dim}
      hidden_depth: 2
